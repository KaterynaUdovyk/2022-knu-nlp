{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf34dd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG file id =  1HqD1LueAC1We0Bgum4qNxxCU6VJZW3yW\n",
      "LOG download url =  https://drive.google.com/uc?id=1HqD1LueAC1We0Bgum4qNxxCU6VJZW3yW\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "#url_testDATA='https://drive.google.com/file/d/1q8_G19zYuD4C2l8u4CrGe_yiitjI1h2I/view?usp=sharing'\n",
    "url_trainDATA='https://drive.google.com/file/d/1HqD1LueAC1We0Bgum4qNxxCU6VJZW3yW/view?usp=sharing'\n",
    "\n",
    "#https://www.kaggle.com/datatattle/email-classification-nlp?select=SMS_train.csv\n",
    "url=url_trainDATA\n",
    "file_id=url.split('/')[-2]\n",
    "print('LOG file id = ',file_id)\n",
    "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
    "print('LOG download url = ', dwn_url)\n",
    "\n",
    "df = pd.read_csv(dwn_url, encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d348b1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   S. No.                                       Message_body     Label\n",
      "0       1                         Rofl. Its true to its name  Non-Spam\n",
      "1       2  The guy did some bitching but I acted like i'd...  Non-Spam\n",
      "2       3  Pity, * was in mood for that. So...any other s...  Non-Spam\n",
      "3       4               Will ü b going to esplanade fr home?  Non-Spam\n",
      "4       5  This is the 2nd time we have tried 2 contact u...      Spam\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "926abffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0f3c64974a462c86052864fe5c0ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4eaaae86a9647488e44297709a1853a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba909942a4e4bfba1e9dd3944343a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7cf03099aed40378740ea45ec983f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "285e880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "text\n",
      "\n",
      "0                             Rofl. Its true to its name\n",
      "1      The guy did some bitching but I acted like i'd...\n",
      "2      Pity, * was in mood for that. So...any other s...\n",
      "3                   Will ü b going to esplanade fr home?\n",
      "4      This is the 2nd time we have tried 2 contact u...\n",
      "                             ...                        \n",
      "952    hows my favourite person today? r u workin har...\n",
      "953                        How much you got for cleaning\n",
      "954    Sorry da. I gone mad so many pending works wha...\n",
      "955                                   Wat time ü finish?\n",
      "956                      Just glad to be talking to you.\n",
      "Name: Message_body, Length: 957, dtype: object\n",
      "\n",
      "label\n",
      "\n",
      "0      Non-Spam\n",
      "1      Non-Spam\n",
      "2      Non-Spam\n",
      "3      Non-Spam\n",
      "4          Spam\n",
      "         ...   \n",
      "952    Non-Spam\n",
      "953    Non-Spam\n",
      "954    Non-Spam\n",
      "955    Non-Spam\n",
      "956    Non-Spam\n",
      "Name: Label, Length: 957, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('\\ntext\\n')\n",
    "data = df['Message_body']\n",
    "print(data)\n",
    "print('\\nlabel\\n')\n",
    "label = df['Label']\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef0392aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sequence):\n",
    "    tokens = tokenizer.encode_plus(sequence, max_length=512,\n",
    "                                   truncation=True, padding='max_length',\n",
    "                                   add_special_tokens=True, return_token_type_ids=False,\n",
    "                                   return_tensors='tf')\n",
    "    return tokens['input_ids'], tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9c296e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "num_of_elements = 5000\n",
    "\n",
    "Xids = np.zeros((num_of_elements, 512))\n",
    "Xmask = np.zeros((num_of_elements, 512))\n",
    "\n",
    "idx = np.random.randint(0, 250, num_of_elements)  \n",
    "small_dataset = np.array(data)[idx.astype(int)]\n",
    "small_dataset_labels = np.array(label)[idx.astype(int)]\n",
    "\n",
    "labels = np.array(small_dataset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa365992",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sequence in enumerate(small_dataset):\n",
    "    tokens = tokenize(sequence)\n",
    "    Xids[i, :], Xmask[i, :] = tokens[0], tokens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00ee4004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101.,   146.,  1354.,   178.,   112.,   173.,  1243.,  1140.,\n",
       "         170.,  2824.,   117.,  1198.,  1884.,  1116.,  1115.,  1116.,\n",
       "        1103.,  1912.,  1104.,  1645.,   190.,  1243.,  1527.,  1389.,\n",
       "       15292.,  1582.,   119.,  1262.,  1119.,  7871.,  1177.,  1277.,\n",
       "         106.,   102.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f561e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5392dd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFAutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec0e4544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,310,272\n",
      "Trainable params: 108,310,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a34c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input_ids = tf.keras.layers.Input(shape=(512,), name='Message_body', dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(512,), name='Label', dtype='int32')\n",
    "\n",
    "embeddings = bert.bert(input_ids, attention_mask=mask)[1]  # we access the transformer model within our bert object using the bert attribute (eg bert.bert instead of bert)\n",
    "\n",
    "# Classifier head\n",
    "x = tf.keras.layers.Dense(1024, activation ='relu')(embeddings)\n",
    "y = tf.keras.layers.Dense(1, activation ='sigmoid', name='outputs')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
    "\n",
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9c13b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<KerasTensor: shape=(None, 512, 768) dtype=float32 (created by layer 'bert')>, pooler_output=<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'bert')>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.bert(input_ids, attention_mask=mask) # outputs of bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55051b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Message_body (InputLayer)      [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " Label (InputLayer)             [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  108310272   ['Message_body[0][0]',           \n",
      "                                thPoolingAndCrossAt               'Label[0][0]']                  \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 512,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         787456      ['bert[0][1]']                   \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 1)            1025        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,098,753\n",
      "Trainable params: 788,481\n",
      "Non-trainable params: 108,310,272\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cfce900",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47342f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "history = model.fit(\n",
    "    [Xids, Xmask], labels,\n",
    "    validation_split=0.8,\n",
    "    batch_size = 16,\n",
    "    verbose = 1,\n",
    "    epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2a64a3",
   "metadata": {},
   "source": [
    "63/63 [==============================] - 2584s 48s/step - loss: 0.9187 - accuracy: 0.5435 - val_loss: 0.6262 - val_accuracy: 0.7832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ad55d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
