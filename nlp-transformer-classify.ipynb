{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16918bf6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-02T19:50:29.053211Z",
     "iopub.status.busy": "2022-02-02T19:50:29.051528Z",
     "iopub.status.idle": "2022-02-02T19:50:35.400005Z",
     "shell.execute_reply": "2022-02-02T19:50:35.399196Z",
     "shell.execute_reply.started": "2022-02-02T19:33:23.413973Z"
    },
    "papermill": {
     "duration": 6.362856,
     "end_time": "2022-02-02T19:50:35.400181",
     "exception": false,
     "start_time": "2022-02-02T19:50:29.037325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f04a3d9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:50:35.425980Z",
     "iopub.status.busy": "2022-02-02T19:50:35.425397Z",
     "iopub.status.idle": "2022-02-02T19:50:35.941695Z",
     "shell.execute_reply": "2022-02-02T19:50:35.941086Z",
     "shell.execute_reply.started": "2022-02-02T19:33:29.620776Z"
    },
    "papermill": {
     "duration": 0.531228,
     "end_time": "2022-02-02T19:50:35.941822",
     "exception": false,
     "start_time": "2022-02-02T19:50:35.410594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_train = \"../input/covid-19-nlp-text-classification/Corona_NLP_train.csv\"\n",
    "path_test = \"../input/covid-19-nlp-text-classification/Corona_NLP_test.csv\"\n",
    "df_train = pd.read_csv(path_train, encoding = 'latin1')\n",
    "df_test = pd.read_csv(path_test, encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27b1f3ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:50:35.999607Z",
     "iopub.status.busy": "2022-02-02T19:50:35.975192Z",
     "iopub.status.idle": "2022-02-02T19:50:36.014356Z",
     "shell.execute_reply": "2022-02-02T19:50:36.013920Z",
     "shell.execute_reply.started": "2022-02-02T19:33:29.933890Z"
    },
    "papermill": {
     "duration": 0.062136,
     "end_time": "2022-02-02T19:50:36.014475",
     "exception": false,
     "start_time": "2022-02-02T19:50:35.952339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.drop(['UserName', 'ScreenName', 'Location', 'TweetAt'], axis = 1, inplace = True)\n",
    "df_test.drop(['UserName', 'ScreenName', 'Location', 'TweetAt'], axis = 1, inplace = True)\n",
    "df_train = df_train[(df_train.Sentiment == 'Extremely Positive') | (df_train.Sentiment == 'Positive') | (df_train.Sentiment == 'Extremely Negative') | (df_train.Sentiment == 'Negative')]\n",
    "df_test = df_test[(df_test.Sentiment == 'Extremely Positive') | (df_test.Sentiment == 'Positive') | (df_test.Sentiment == 'Extremely Negative') | (df_test.Sentiment == 'Negative')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38628bef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:50:36.044168Z",
     "iopub.status.busy": "2022-02-02T19:50:36.043574Z",
     "iopub.status.idle": "2022-02-02T19:50:36.052175Z",
     "shell.execute_reply": "2022-02-02T19:50:36.052636Z",
     "shell.execute_reply.started": "2022-02-02T19:33:29.983805Z"
    },
    "papermill": {
     "duration": 0.028334,
     "end_time": "2022-02-02T19:50:36.052785",
     "exception": false,
     "start_time": "2022-02-02T19:50:36.024451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_seq_len = 140\n",
    "max_features = 30000\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "def makediglabel(text):\n",
    "    if text in ['Extremely Positive', 'Positive']:\n",
    "        return 0.0\n",
    "    elif text in ['Extremely Negative', 'Negative']:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return -1.0\n",
    "    \n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"@\\S+\", \" \", text)  \n",
    "    text = re.sub(\"https*\\S+\", \" \", text)\n",
    "    text = re.sub(\"www\\S+\", \" \", text)\n",
    "    text = re.sub(\"#\\S+\", \" \", text)\n",
    "    text = re.sub(\"\\d\", \" \", text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = re.sub('\\n', ' ', text)        \n",
    "    text = re.sub('\\s{2,}',' ', text)\n",
    "    text = ' '.join([word for word in text.split(' ') if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "def convert(text):\n",
    "    tok = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem = [lemmatizer.lemmatize(t) for t in tok]\n",
    "    res = [dictionary.index(i) for i in lem]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bbfe90e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:50:36.102668Z",
     "iopub.status.busy": "2022-02-02T19:50:36.092400Z",
     "iopub.status.idle": "2022-02-02T19:50:38.892345Z",
     "shell.execute_reply": "2022-02-02T19:50:38.891840Z",
     "shell.execute_reply.started": "2022-02-02T19:33:30.004605Z"
    },
    "papermill": {
     "duration": 2.829831,
     "end_time": "2022-02-02T19:50:38.892479",
     "exception": false,
     "start_time": "2022-02-02T19:50:36.062648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.OriginalTweet = df_train.OriginalTweet.apply(clean_text)\n",
    "df_test.OriginalTweet = df_test.OriginalTweet.apply(clean_text)\n",
    "df_train.Sentiment = df_train.Sentiment.apply(makediglabel)\n",
    "df_test.Sentiment = df_test.Sentiment.apply(makediglabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3860a6dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:50:38.921498Z",
     "iopub.status.busy": "2022-02-02T19:50:38.920782Z",
     "iopub.status.idle": "2022-02-02T19:50:38.922965Z",
     "shell.execute_reply": "2022-02-02T19:50:38.923371Z",
     "shell.execute_reply.started": "2022-02-02T19:33:32.819574Z"
    },
    "papermill": {
     "duration": 0.016196,
     "end_time": "2022-02-02T19:50:38.923504",
     "exception": false,
     "start_time": "2022-02-02T19:50:38.907308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = df_train.OriginalTweet\n",
    "Y_train = df_train.Sentiment\n",
    "X_test = df_test.OriginalTweet\n",
    "Y_test = df_test.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6640b51b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:50:38.972345Z",
     "iopub.status.busy": "2022-02-02T19:50:38.965960Z",
     "iopub.status.idle": "2022-02-02T19:50:49.163349Z",
     "shell.execute_reply": "2022-02-02T19:50:49.162843Z",
     "shell.execute_reply.started": "2022-02-02T19:33:32.825979Z"
    },
    "papermill": {
     "duration": 10.23021,
     "end_time": "2022-02-02T19:50:49.163487",
     "exception": false,
     "start_time": "2022-02-02T19:50:38.933277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "whole_text = \"\"\n",
    "for i in X_train:\n",
    "    whole_text += i + ' '\n",
    "for i in X_test:\n",
    "    whole_text += i + ' '\n",
    "tokens = word_tokenize(whole_text)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemtok = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "dictionary = list(set(lemtok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f9fa8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:50:49.199427Z",
     "iopub.status.busy": "2022-02-02T19:50:49.198758Z",
     "iopub.status.idle": "2022-02-02T19:55:15.042792Z",
     "shell.execute_reply": "2022-02-02T19:55:15.043920Z",
     "shell.execute_reply.started": "2022-02-02T19:33:43.574567Z"
    },
    "papermill": {
     "duration": 265.870539,
     "end_time": "2022-02-02T19:55:15.044165",
     "exception": false,
     "start_time": "2022-02-02T19:50:49.173626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train.apply(convert)\n",
    "X_test = X_test.apply(convert)\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(X_train, maxlen = max_seq_len)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(X_test, maxlen = max_seq_len)\n",
    "y_train = np.asarray(Y_train).astype(\"float32\")\n",
    "y_test = np.asarray(Y_test).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "181035d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:55:15.085426Z",
     "iopub.status.busy": "2022-02-02T19:55:15.084651Z",
     "iopub.status.idle": "2022-02-02T19:55:15.089837Z",
     "shell.execute_reply": "2022-02-02T19:55:15.090935Z",
     "shell.execute_reply.started": "2022-02-02T19:38:09.568000Z"
    },
    "papermill": {
     "duration": 0.030655,
     "end_time": "2022-02-02T19:55:15.091146",
     "exception": false,
     "start_time": "2022-02-02T19:55:15.060491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44f35fa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:55:15.130374Z",
     "iopub.status.busy": "2022-02-02T19:55:15.129589Z",
     "iopub.status.idle": "2022-02-02T19:55:15.132675Z",
     "shell.execute_reply": "2022-02-02T19:55:15.133260Z",
     "shell.execute_reply.started": "2022-02-02T19:38:09.578341Z"
    },
    "papermill": {
     "duration": 0.02671,
     "end_time": "2022-02-02T19:55:15.133433",
     "exception": false,
     "start_time": "2022-02-02T19:55:15.106723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c1df1df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:55:15.172335Z",
     "iopub.status.busy": "2022-02-02T19:55:15.171580Z",
     "iopub.status.idle": "2022-02-02T19:55:18.122467Z",
     "shell.execute_reply": "2022-02-02T19:55:18.121842Z",
     "shell.execute_reply.started": "2022-02-02T19:48:57.914484Z"
    },
    "papermill": {
     "duration": 2.97386,
     "end_time": "2022-02-02T19:55:18.122608",
     "exception": false,
     "start_time": "2022-02-02T19:55:15.148748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-02 19:55:15.368668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-02 19:55:15.492311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-02 19:55:15.493409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-02 19:55:15.501472: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-02 19:55:15.502834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-02 19:55:15.503815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-02 19:55:15.504747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-02 19:55:17.579811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-02 19:55:17.580716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-02 19:55:17.581494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-02 19:55:17.582100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 32  # Embedding size for each token\n",
    "num_heads = 4  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = layers.Input(shape=(max_seq_len,))\n",
    "embedding_layer = TokenAndPositionEmbedding(max_seq_len, max_features, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ee8d28b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:55:18.152411Z",
     "iopub.status.busy": "2022-02-02T19:55:18.146869Z",
     "iopub.status.idle": "2022-02-02T19:55:43.943664Z",
     "shell.execute_reply": "2022-02-02T19:55:43.944142Z",
     "shell.execute_reply.started": "2022-02-02T19:49:03.233243Z"
    },
    "papermill": {
     "duration": 25.810799,
     "end_time": "2022-02-02T19:55:43.944300",
     "exception": false,
     "start_time": "2022-02-02T19:55:18.133501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-02 19:55:18.224699: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1046/1046 [==============================] - 10s 8ms/step - loss: 0.6000 - accuracy: 0.6312 - val_loss: 0.4040 - val_accuracy: 0.8135\n",
      "Epoch 2/3\n",
      "1046/1046 [==============================] - 8s 7ms/step - loss: 0.2755 - accuracy: 0.8917 - val_loss: 0.3208 - val_accuracy: 0.8606\n",
      "Epoch 3/3\n",
      "1046/1046 [==============================] - 8s 7ms/step - loss: 0.1743 - accuracy: 0.9362 - val_loss: 0.3266 - val_accuracy: 0.8685\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs=3, validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e179867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T19:55:44.183892Z",
     "iopub.status.busy": "2022-02-02T19:55:44.182900Z",
     "iopub.status.idle": "2022-02-02T19:55:44.516944Z",
     "shell.execute_reply": "2022-02-02T19:55:44.516485Z",
     "shell.execute_reply.started": "2022-02-02T19:49:46.031273Z"
    },
    "papermill": {
     "duration": 0.454909,
     "end_time": "2022-02-02T19:55:44.517086",
     "exception": false,
     "start_time": "2022-02-02T19:55:44.062177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.3265705704689026\n",
      "Test accuracy: 0.8685120940208435\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 327.465456,
   "end_time": "2022-02-02T19:55:48.238321",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-02T19:50:20.772865",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
