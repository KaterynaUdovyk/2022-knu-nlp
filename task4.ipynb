{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13ce2c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "023397e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"train.csv\")\n",
    "data_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b6404fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^ a-z]', '', text)\n",
    "    while text.find('  ') != -1:\n",
    "        text = text.replace('  ', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83e114a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['clean_text']= data_train['Text'].apply(lambda x:clear_text(x))\n",
    "data_test['clean_text']= data_test['Text'].apply(lambda x:clear_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b263a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['clean_text'] = data_train['clean_text'].apply(lambda x:word_tokenize(x))\n",
    "data_test['clean_text'] = data_test['clean_text'].apply(lambda x:word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f20d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    filtered_text = []\n",
    "    for w in text:\n",
    "        if w not in stop_words:\n",
    "            filtered_text.append(w)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "576034e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['clean_text'] = data_train['clean_text'].apply(lambda x:remove_stop_words(x))\n",
    "data_test['clean_text'] = data_test['clean_text'].apply(lambda x:remove_stop_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96bb2b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer(text):\n",
    "    return [wordnet_lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "data_train['clean_text'] = data_train['clean_text'].apply(lambda x:lemmatizer(x))\n",
    "data_test['clean_text'] = data_test['clean_text'].apply(lambda x:lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c926d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_text(data):\n",
    "    text = []\n",
    "    for i in data:\n",
    "        for word in i:\n",
    "            text.append(word)\n",
    "    return text\n",
    "\n",
    "text = to_text(data_train['clean_text'])\n",
    "text += to_text(data_test['clean_text'])\n",
    "text.sort()\n",
    "dictionary = []\n",
    "for i in text:\n",
    "    if i not in dictionary:\n",
    "        dictionary.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "580af814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numbers(text):\n",
    "    res = []\n",
    "    for word in text:\n",
    "        res.append(dictionary.index(word))\n",
    "    return res\n",
    "\n",
    "def convert_to_text(numbers):\n",
    "    res = []\n",
    "    for num in numbers:\n",
    "        res.append(dictionary[num])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d762a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['numbers'] = data_train['clean_text'].apply(lambda x:convert_to_numbers(x))\n",
    "data_test['numbers'] = data_test['clean_text'].apply(lambda x:convert_to_numbers(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2a393a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#good: happy, love, surprise\n",
    "#bad: sadness, anger, fear\n",
    "\n",
    "def t_or_f(emotion):\n",
    "    if emotion == 'happy' or emotion == 'love' or emotion == 'surprise':\n",
    "        return 1        \n",
    "    else:        #elif emotioin == 'sadness' or 'anger' or 'fear': return 0\n",
    "        return 0\n",
    "    \n",
    "data_train['Emotion_in_digit'] = data_train['Emotion'].apply(lambda x:t_or_f(x))\n",
    "data_test['Emotion_in_digit'] = data_test['Emotion'].apply(lambda x:t_or_f(x))\n",
    "\n",
    "# data_train[['Emotion','Emotion_in_digit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4b16836",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train[['Emotion_in_digit', 'numbers']]\n",
    "data_test = data_test[['Emotion_in_digit', 'numbers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91f4d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=30000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for j in sequence:\n",
    "            results[i, j] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d546ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(data_train['numbers'])\n",
    "x_test = vectorize_sequences(data_test['numbers'])\n",
    "y_train = np.asarray(data_train['Emotion_in_digit']).astype(\"float32\")\n",
    "y_test = np.asarray(data_test['Emotion_in_digit']).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80adde4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000  # Only consider the top 20k words\n",
    "maxlen = 200  # Only consider the first 200 words of each movie review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fa2b236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 128)        98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,757,761\n",
      "Trainable params: 2,757,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input for variable-length sequences of integers\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "x = layers.Embedding(max_features, 128)(inputs)\n",
    "# Add 2 bidirectional LSTMs\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "# Add a classifier\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d316abbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 Training sequences\n",
      "25000 Validation sequences\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(\n",
    "    num_words=max_features\n",
    ")\n",
    "print(len(x_train), \"Training sequences\")\n",
    "print(len(x_val), \"Validation sequences\")\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2db9feb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 389s 490ms/step - loss: 0.3943 - accuracy: 0.8222 - val_loss: 0.3381 - val_accuracy: 0.8621\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 453s 579ms/step - loss: 0.2103 - accuracy: 0.9216 - val_loss: 0.3316 - val_accuracy: 0.8598\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 425s 543ms/step - loss: 0.1264 - accuracy: 0.9565 - val_loss: 0.3982 - val_accuracy: 0.8581\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 430s 549ms/step - loss: 0.0779 - accuracy: 0.9740 - val_loss: 0.4358 - val_accuracy: 0.8506\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 338s 432ms/step - loss: 0.0801 - accuracy: 0.9714 - val_loss: 0.4964 - val_accuracy: 0.8417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x214029696c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c03c7fa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 2294s 13s/step - loss: 0.8032 - accuracy: 0.4232\n",
      "Test score: 0.8032044172286987\n",
      "Test accuracy: 0.42318257689476013\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=1) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fadc424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a2ac82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
