{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "80b87c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my training link: https://drive.google.com/uc?id=1Jg3l_AmdkfEIIiLAuwlwyybpXYt93Vvp\n",
      "my testing link: https://drive.google.com/uc?id=1Ytg9xAeZu4p-c6mcKDodHI3W7wLJ4sIo\n",
      "{'drug', 'procedure', 'pemetrexed', 'phosphate', 'investigator', 'within', 'factor', 'investigational', 'syndrome', 'required', 'androgen', 'solid', 'line', 'eligible', 'opinion', 'willingness', 'rectal', 'ovarian', 'associated', 'pleural', 'prostate', 'infection', 'grade', 'tract', 'patient', 'less_than', 'risk', 'ctcae', 'considered', 'receive', 'concurrent', 'concomitant', 'subject', 'renal', 'intra', 'currently', 'node', 'pet', 'giant', 'cateder', 'de', 'terminology', 'limit', 'york', 'clearance', 'ect', 'hodgkin', 'malignant', 'metastasis', 'lymph', 'regional', 'nci', 'similar', 'positron_emission', 'melanoma', 'placement', 'pointes', 'jak', 'paclitaxel', 'characteristic', 'use', 'laboratory', 'able', 'cancer', 'clinic', 'status', 'colorectal', 'diagnosis', 'bone', 'pregnant', 'esophagus', 'creatinine', 'following', 'venous', 'large', 'except', 'zero', 'recombinant', 'toxicity', 'chemotherapy', 'chemical', 'emission', 'recurrent', 'oral', 'failure', 'event', 'undergone', 'visual', 'staff', 'taxane', 'taking', 'allergic', 'min', 'peripheral', 'female', 'immunoglobulin', 'see', 'one', 'bi', 'fallopian', 'must', 'inhibitor', 'mesothelioma', 'nyha', 'attributed', 'acuity', 'another', 'least', 'gastrointestinal', 'imaging', 'radiotherapy', 'lymphoma', 'angiogenesis', 'three', 'two', 'regimen', 'dexamethasone', 'best', 'tumor', 'association', 'diffuse', 'uveal', 'central', 'multiple', 'compound', 'intervention', 'congestive', 'generally', 'cyclophosphamide', 'safety', 'mellitus', 'adverse', 'high', 'intracavitary', 'torsades', 'doc', 'class', 'non', 'condition', 'understand', 'persistent', 'precancerous', 'heart', 'resonance', 'mri', 'ct', 'visceral', 'platinum', 'criterion', 'history', 'niacinamide', 'prevent', 'previous', 'common', 'defined', 'inclusion', 'management', 'verrucous', 'incb', 'liposomal', 'cdligand', 'antibody', 'active', 'hormone', 'carcinoma', 'camptothecin', 'disease', 'new', 'surgery', 'cytotoxic', 'version', 'insufficiency', 'causing', 'involved', 'reaction', 'nivolumab', 'baseline', 'diabetes', 'vitiligo', 'presence', 'cell', 'potential', 'busulfan', 'appendix', 'acceptable', 'skin', 'recovered', 'prior', 'administration', 'iv', 'tomography', 'glioblastoma', 'intraocular', 'examination', 'tube', 'biologic', 'corrected', 'determined', 'revealed', 'hepatitis', 'iii', 'entry', 'institute', 'undergo', 'allowed', 'indwelling', 'additional', 'magnetic', 'scan', 'alopecia', 'adenocarcinoma', 'accepted', 'agent', 'twelve', 'malabsorption', 'component', 'stage', 'cavity', 'including', 'month', 'thalidomide', 'pazopanib', 'improvement', 'effect', 'recent', 'lactating', 'cardiovascular', 'vaccination', 'composition', 'ocular', 'bortezomib', 'etoposide', 'used', 'computed', 'kidney', 'cns', 'fifty', 'monoclonal', 'inflammatory', 'doxorubicin', 'myeloma', 'study', 'therapy', 'treatment', 'dasatinib', 'kw', 'national', 'multiforme', 'ml', 'bendamustine', 'hydrochloride'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import re, string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "train_url = 'https://drive.google.com/file/d/1Jg3l_AmdkfEIIiLAuwlwyybpXYt93Vvp/view?usp=sharing'\n",
    "train_url_ = 'https://drive.google.com/uc?id=' + train_url.split('/')[-2]\n",
    "\n",
    "\n",
    "test_url = 'https://drive.google.com/file/d/1Ytg9xAeZu4p-c6mcKDodHI3W7wLJ4sIo/view?usp=sharing'\n",
    "test_url_ = 'https://drive.google.com/uc?id=' + test_url.split('/')[-2]\n",
    "# df = pd.read_csv(url_)\n",
    "# print(url.split('/')[-2])\n",
    "\n",
    "print('my training link:', train_url_)\n",
    "print('my testing link:', test_url_)\n",
    "\n",
    "\n",
    "df.train = pd.read_csv(train_url_, header= None) # got the dataframe\n",
    "df.test = pd.read_csv(test_url_, header= None)\n",
    "\n",
    "#print('training file:\\n', df.train.head(n = len(df.train)))\n",
    "\n",
    "\n",
    "train_data_set = list(df.train[1])\n",
    "test_data_set = list(df.test[1])\n",
    "\n",
    "\n",
    "train_in_string = ''\n",
    "for i in train_data_set:\n",
    "    train_in_string += (' ' + i)\n",
    "    \n",
    "test_in_string = ''\n",
    "for j in test_data_set:\n",
    "    test_in_string += (' ' + j)\n",
    "        \n",
    "def cleaning(label):\n",
    "\n",
    "    filtered = re.sub(r'[^\\w\\s]', '', label)\n",
    "    filtered = re.sub(\"@\\S+\", \"\", filtered)\n",
    "    filtered = re.sub(\"https*\\S+\", \"\", filtered)\n",
    "    filtered = re.sub(\"\\d\", \"\", filtered)\n",
    "    filtered = re.sub(\"#\\S+\", \"\", filtered)\n",
    "\n",
    "    filtered = filtered.lower()\n",
    "    #print(filtered)\n",
    "    tokens = word_tokenize(filtered)\n",
    "    #print(tokens)\n",
    "    filtered_tokens = []\n",
    "    for word in tokens:\n",
    "        if word not in stop_words:\n",
    "            filtered_tokens.append(word)#тут добавляю в новый список только те слова, которые не являются стоп словами\n",
    "    #print(filtered_tokens)\n",
    "\n",
    "    #print(filtered_tokens_set)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    #stemmer = PorterStemmer()\n",
    "    # stemmed_tokens = [stemmer.stem(s) for s in filtered_tokens_set]\n",
    "    # print('stemming:', stemmed_tokens)\n",
    "\n",
    "    lemmatized = [lemmatizer.lemmatize(l) for l in filtered_tokens]\n",
    "    lemmatizer = set(lemmatized)\n",
    "    return lemmatizer\n",
    "\n",
    "\n",
    "train_cleaned_data = cleaning(train_in_string)\n",
    "test_cleaned_data = cleaning(test_in_string)\n",
    "print(train_cleaned_data)\n",
    "#print(test_cleaned_data)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b99a8fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "train_label = []\n",
    "test_label = []\n",
    "\n",
    "for label in list(df.train[0]):\n",
    "    if label == '__label__0':\n",
    "        train_label.append(0)\n",
    "    if label == '__label__1':\n",
    "        train_label.append(1)\n",
    "\n",
    "for label_test in list(df.test[0]):\n",
    "    if label_test == '__label__0':\n",
    "        test_label.append(0)\n",
    "    if label_test == '__label__1':\n",
    "        test_label.append(1)\n",
    "\n",
    "print(train_label)\n",
    "print(test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "2afed14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "y_train = np.asarray(train_label).astype(\"float32\")\n",
    "y_test = np.asarray(test_label).astype(\"float32\")\n",
    "\n",
    "print(train_label)\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f8915e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def vectorize(ten):\n",
    "    vectorizer = CountVectorizer()\n",
    "    sparse_matrix = vectorizer.fit_transform(ten)\n",
    "    vectorizer.get_feature_names_out()\n",
    "    \n",
    "    return sparse_matrix.toarray()\n",
    "    \n",
    "train_vect = vectorize(train_cleaned_data) \n",
    "test_vect = vectorize(test_cleaned_data) \n",
    "print(train_vect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "243d54da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def embadding(sequences, dimension=10):\n",
    "  \n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for j in sequence:\n",
    "            results[i, j] = 1.\n",
    "    return results\n",
    "\n",
    "print(type(x_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "5f06e058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_train = embadding(train_vect)\n",
    "\n",
    "x_test = embadding(test_vect)\n",
    "print(x_train)\n",
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b5acd831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "5c62666e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x000001FCD96E98C8>\n"
     ]
    }
   ],
   "source": [
    "#creating a model with an activation function - relu\n",
    "the_first_model = tf.keras.Sequential(name = 'model')# sequential() allows you to create models layer-by-layer \n",
    " \n",
    "the_first_model.add(layers.Dense(5, activation='relu', name = 'layer1'))\n",
    "\n",
    "\"\"\"The function returns 0 if it receives any negative input,\n",
    "but for any positive value x it returns that value back\"\"\"\n",
    "\n",
    "the_first_model.add(layers.Dense(1, activation='sigmoid', name = 'layer3'))\n",
    "\n",
    "print(the_first_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "3d72dd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 5)                 20        \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26\n",
      "Trainable params: 26\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "the_first_model.build(input_shape=(None, 3))\n",
    "the_first_model.summary()\n",
    "\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "8a044b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "the_first_model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"], run_eagerly=True)\n",
    "\n",
    "\n",
    "print(type(x_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "48155849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18456\\4251707910.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                     \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                     verbose =5)\n\u001b[0m",
      "\u001b[1;32md:\\pythonproject2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pythonproject2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1225\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1227\u001b[1;33m           raise ValueError('Unexpected result of `train_function` '\n\u001b[0m\u001b[0;32m   1228\u001b[0m                            \u001b[1;34m'(Empty logs). Please use '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m                            \u001b[1;34m'`Model.compile(..., run_eagerly=True)`, or '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "history = the_first_model.fit(x_train,\n",
    "                   y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=300,\n",
    "                    validation_split=2,\n",
    "                    shuffle = True,\n",
    "                    verbose =5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "507e67ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = the_first_model.fit(train_embadding, train_label, epochs=10, batch_size=11, validation_split=2, shuffle = True, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "519483e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 5)                 20        \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26\n",
      "Trainable params: 26\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(the_first_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc3461a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
