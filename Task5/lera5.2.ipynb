{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e7ff89",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-07T12:54:00.124295Z",
     "iopub.status.busy": "2022-02-07T12:54:00.123094Z",
     "iopub.status.idle": "2022-02-07T12:54:06.549366Z",
     "shell.execute_reply": "2022-02-07T12:54:06.548581Z",
     "shell.execute_reply.started": "2022-02-07T12:53:26.395553Z"
    },
    "papermill": {
     "duration": 6.442995,
     "end_time": "2022-02-07T12:54:06.549546",
     "exception": false,
     "start_time": "2022-02-07T12:54:00.106551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a91b27b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T12:54:06.578744Z",
     "iopub.status.busy": "2022-02-07T12:54:06.578133Z",
     "iopub.status.idle": "2022-02-07T12:54:07.687305Z",
     "shell.execute_reply": "2022-02-07T12:54:07.687787Z",
     "shell.execute_reply.started": "2022-02-07T12:53:32.942059Z"
    },
    "papermill": {
     "duration": 1.124604,
     "end_time": "2022-02-07T12:54:07.687985",
     "exception": false,
     "start_time": "2022-02-07T12:54:06.563381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df size:  (154460, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   eng      ukr\n",
       " 0  Hi.   Вітаю!\n",
       " 1  Hi.  Привіт.\n",
       " 2  Hi.  Привіт!,\n",
       "                                                       eng  \\\n",
       " 154457  If forests cover 9.4% of the earth's surface, ...   \n",
       " 154458  The Tatoeba Project, which can be found online...   \n",
       " 154459  I've heard that you should never date anyone w...   \n",
       " \n",
       "                                                       ukr  \n",
       " 154457  Якщо ліси складають 9,4% поверхні Землі, і якщ...  \n",
       " 154458  Проект \"Татоеба\", що знаходиться онлайн за адр...  \n",
       " 154459  Я чула, що не слід зустрічатися з кимось, кому...  )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file = \"../input/ukr-eng/ukr.txt\"\n",
    "df = pd.read_csv(text_file, sep='\\t', usecols=[0, 1])\n",
    "df.columns = ['eng', 'ukr']\n",
    "\n",
    "print(\"Df size: \", df.shape)\n",
    "df.head(3), df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a51df7b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T12:54:07.734646Z",
     "iopub.status.busy": "2022-02-07T12:54:07.733825Z",
     "iopub.status.idle": "2022-02-07T12:54:08.167578Z",
     "shell.execute_reply": "2022-02-07T12:54:08.168182Z",
     "shell.execute_reply.started": "2022-02-07T12:53:34.490702Z"
    },
    "papermill": {
     "duration": 0.467379,
     "end_time": "2022-02-07T12:54:08.168356",
     "exception": false,
     "start_time": "2022-02-07T12:54:07.700977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>ukr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154457</th>\n",
       "      <td>If forests cover 9.4% of the earth's surface, ...</td>\n",
       "      <td>Якщо ліси складають 9,4% поверхні Землі, і якщ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154458</th>\n",
       "      <td>The Tatoeba Project, which can be found online...</td>\n",
       "      <td>Проект \"Татоеба\", що знаходиться онлайн за адр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154459</th>\n",
       "      <td>I have heard that you should never date anyone...</td>\n",
       "      <td>Я чула, що не слід зустрічатися з кимось, кому...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "154457  If forests cover 9.4% of the earth's surface, ...   \n",
       "154458  The Tatoeba Project, which can be found online...   \n",
       "154459  I have heard that you should never date anyone...   \n",
       "\n",
       "                                                      ukr  \n",
       "154457  Якщо ліси складають 9,4% поверхні Землі, і якщ...  \n",
       "154458  Проект \"Татоеба\", що знаходиться онлайн за адр...  \n",
       "154459  Я чула, що не слід зустрічатися з кимось, кому...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \n",
    "                \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \n",
    "                \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n",
    "                \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "def clean_text(text, language):\n",
    "  if language == 'eng':\n",
    "    text = ' '.join([contractions[word] if word in contractions else word for word in text.split()])\n",
    "  return text\n",
    "\n",
    "for language in df:\n",
    "  df[language] = df[language].apply(lambda text : clean_text(text, language))\n",
    "\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00b03313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T12:54:08.198402Z",
     "iopub.status.busy": "2022-02-07T12:54:08.197450Z",
     "iopub.status.idle": "2022-02-07T12:54:08.279357Z",
     "shell.execute_reply": "2022-02-07T12:54:08.279802Z",
     "shell.execute_reply.started": "2022-02-07T12:53:35.263611Z"
    },
    "papermill": {
     "duration": 0.098627,
     "end_time": "2022-02-07T12:54:08.279978",
     "exception": false,
     "start_time": "2022-02-07T12:54:08.181351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>ukr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[start] Hi.[end]</td>\n",
       "      <td>Вітаю!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[start] Hi.[end]</td>\n",
       "      <td>Привіт.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[start] Hi.[end]</td>\n",
       "      <td>Привіт!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                eng      ukr\n",
       "0  [start] Hi.[end]   Вітаю!\n",
       "1  [start] Hi.[end]  Привіт.\n",
       "2  [start] Hi.[end]  Привіт!"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['eng'] = df['eng'].apply(lambda i : \"[start] \" + i + \"[end]\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88fb2668",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T12:54:08.310477Z",
     "iopub.status.busy": "2022-02-07T12:54:08.309523Z",
     "iopub.status.idle": "2022-02-07T12:54:08.749104Z",
     "shell.execute_reply": "2022-02-07T12:54:08.749583Z",
     "shell.execute_reply.started": "2022-02-07T12:53:35.477491Z"
    },
    "papermill": {
     "duration": 0.456358,
     "end_time": "2022-02-07T12:54:08.749757",
     "exception": false,
     "start_time": "2022-02-07T12:54:08.293399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[start] Hi.[end]', 'Вітаю!'),\n",
       " ('[start] Hi.[end]', 'Привіт.'),\n",
       " ('[start] Hi.[end]', 'Привіт!')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_e_list = list(df.to_records(index=False)) # преобразование df в список кортежей(массив записей NumPy)\n",
    "u_e_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf33495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T12:54:08.780915Z",
     "iopub.status.busy": "2022-02-07T12:54:08.779978Z",
     "iopub.status.idle": "2022-02-07T12:54:08.839530Z",
     "shell.execute_reply": "2022-02-07T12:54:08.840072Z",
     "shell.execute_reply.started": "2022-02-07T12:53:36.433617Z"
    },
    "papermill": {
     "duration": 0.076743,
     "end_time": "2022-02-07T12:54:08.840256",
     "exception": false,
     "start_time": "2022-02-07T12:54:08.763513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training pairs: (123568, 2)\n",
      "test pairs: (15446, 2)\n",
      "validation pairs: (15446, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>ukr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[start] Why am I still here?[end]</td>\n",
       "      <td>Чому я й досі тут?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[start] I am stunned.[end]</td>\n",
       "      <td>Я приголомшений.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 eng                 ukr\n",
       "0  [start] Why am I still here?[end]  Чому я й досі тут?\n",
       "1         [start] I am stunned.[end]    Я приголомшений."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, shuffle=True, random_state=42)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"training pairs:\", train_df.shape)\n",
    "print(\"test pairs:\", test_df.shape)\n",
    "print(\"validation pairs:\", val_df.shape)\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a16ab35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T12:54:08.875140Z",
     "iopub.status.busy": "2022-02-07T12:54:08.874283Z",
     "iopub.status.idle": "2022-02-07T12:54:09.353201Z",
     "shell.execute_reply": "2022-02-07T12:54:09.353733Z",
     "shell.execute_reply.started": "2022-02-07T12:53:36.545795Z"
    },
    "papermill": {
     "duration": 0.49926,
     "end_time": "2022-02-07T12:54:09.353913",
     "exception": false,
     "start_time": "2022-02-07T12:54:08.854653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[start] Why am I still here?[end]', 'Чому я й досі тут?'),\n",
       " ('[start] I am stunned.[end]', 'Я приголомшений.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list = list(train_df.to_records(index=False)) \n",
    "test_list = list(test_df.to_records(index=False)) \n",
    "val_list = list(val_df.to_records(index=False))\n",
    "train_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5fe7040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T12:54:09.387077Z",
     "iopub.status.busy": "2022-02-07T12:54:09.386371Z",
     "iopub.status.idle": "2022-02-07T12:54:24.642012Z",
     "shell.execute_reply": "2022-02-07T12:54:24.642552Z"
    },
    "papermill": {
     "duration": 15.274003,
     "end_time": "2022-02-07T12:54:24.642752",
     "exception": false,
     "start_time": "2022-02-07T12:54:09.368749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,noverbose,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_DUPLICATE_LIB_OK=True\n",
      "   KMP_INIT_AT_FORK=FALSE\n",
      "   KMP_SETTINGS=1\n",
      "   KMP_WARNINGS=0\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=true\n",
      "   KMP_ENABLE_TASK_THROTTLING=true\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=8M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=4\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USE_YIELD=1\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=false\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=1\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED: deprecated; max-active-levels-var=1\n",
      "   OMP_NUM_THREADS: value is not defined\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=8M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='noverbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n",
      "2022-02-07 12:54:09.429598: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-02-07 12:54:11.141124: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "vocab_size = 17000\n",
    "sequence_length = 25\n",
    "batch_size = 64\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "ukr_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,)\n",
    "eng_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size, output_mode=\"int\",output_sequence_length=sequence_length + 1, standardize=custom_standardization,)\n",
    "train_eng_texts = [pair[0] for pair in u_e_list]\n",
    "train_ukr_texts = [pair[1] for pair in u_e_list]\n",
    "eng_vectorization.adapt(train_eng_texts)\n",
    "ukr_vectorization.adapt(train_ukr_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c65717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T12:54:24.681358Z",
     "iopub.status.busy": "2022-02-07T12:54:24.680676Z",
     "iopub.status.idle": "2022-02-07T12:54:24.773267Z",
     "shell.execute_reply": "2022-02-07T12:54:24.773758Z"
    },
    "papermill": {
     "duration": 0.113592,
     "end_time": "2022-02-07T12:54:24.773948",
     "exception": false,
     "start_time": "2022-02-07T12:54:24.660356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eng_vocabulary = eng_vectorization.get_vocabulary()\n",
    "ukr_vocabulary = ukr_vectorization.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbd3d330",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T12:54:24.808984Z",
     "iopub.status.busy": "2022-02-07T12:54:24.808354Z",
     "iopub.status.idle": "2022-02-07T12:54:26.833585Z",
     "shell.execute_reply": "2022-02-07T12:54:26.834070Z"
    },
    "papermill": {
     "duration": 2.044344,
     "end_time": "2022-02-07T12:54:26.834244",
     "exception": false,
     "start_time": "2022-02-07T12:54:24.789900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_dataset(eng, ukr):\n",
    "    eng = eng_vectorization(eng)\n",
    "    ukr = ukr_vectorization(ukr)\n",
    "    return ({\"encoder_inputs\": ukr, \"decoder_inputs\": eng[:, :-1],}, eng[:, 1:])\n",
    "\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, ukr_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    ukr_texts = list(ukr_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, ukr_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "\n",
    "train_ds = make_dataset(train_list)\n",
    "val_ds = make_dataset(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dca2c20c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T12:54:26.869425Z",
     "iopub.status.busy": "2022-02-07T12:54:26.868579Z",
     "iopub.status.idle": "2022-02-07T12:54:26.895111Z",
     "shell.execute_reply": "2022-02-07T12:54:26.894565Z"
    },
    "papermill": {
     "duration": 0.045228,
     "end_time": "2022-02-07T12:54:26.895256",
     "exception": false,
     "start_time": "2022-02-07T12:54:26.850028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim \n",
    "        self.dense_dim = dense_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.dense_proj = keras.Sequential([layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),])\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
    "        attention_output = self.attention(query=inputs, value=inputs, key=inputs, attention_mask=padding_mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=embed_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.attention_2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.dense_proj = keras.Sequential([layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),])\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "\n",
    "        attention_output_1 = self.attention_1(query=inputs, value=inputs, key=inputs, attention_mask=causal_mask)\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        \n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,)\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat([tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], axis=0,)\n",
    "        return tf.tile(mask, mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2444e1d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T12:54:26.930584Z",
     "iopub.status.busy": "2022-02-07T12:54:26.929973Z",
     "iopub.status.idle": "2022-02-07T12:54:27.979655Z",
     "shell.execute_reply": "2022-02-07T12:54:27.978249Z"
    },
    "papermill": {
     "duration": 1.068646,
     "end_time": "2022-02-07T12:54:27.979876",
     "exception": false,
     "start_time": "2022-02-07T12:54:26.911230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "latent_dim = 2048 # количество нейронов для Dense слоев Encoder-а и Decoder-а\n",
    "num_heads = 4\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x) #Encoder-1\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs) #Decoder-1\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d91cca97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T12:54:28.032227Z",
     "iopub.status.busy": "2022-02-07T12:54:28.020387Z",
     "iopub.status.idle": "2022-02-07T15:19:05.803826Z",
     "shell.execute_reply": "2022-02-07T15:19:05.802803Z"
    },
    "papermill": {
     "duration": 8677.805864,
     "end_time": "2022-02-07T15:19:05.804142",
     "exception": false,
     "start_time": "2022-02-07T12:54:27.998278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positional_embedding (Positiona (None, None, 128)    2179200     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder (Transforme (None, None, 128)    790784      positional_embedding[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, None, 17000)  5427048     decoder_inputs[0][0]             \n",
      "                                                                 transformer_encoder[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 8,397,032\n",
      "Trainable params: 8,397,032\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "1931/1931 [==============================] - 1391s 718ms/step - loss: 0.8231 - accuracy: 0.5158 - val_loss: 0.5233 - val_accuracy: 0.6527\n",
      "Epoch 2/6\n",
      "1931/1931 [==============================] - 1411s 731ms/step - loss: 0.4781 - accuracy: 0.6790 - val_loss: 0.4022 - val_accuracy: 0.7183\n",
      "Epoch 3/6\n",
      "1931/1931 [==============================] - 1409s 730ms/step - loss: 0.3675 - accuracy: 0.7340 - val_loss: 0.3588 - val_accuracy: 0.7432\n",
      "Epoch 4/6\n",
      "1931/1931 [==============================] - 1412s 731ms/step - loss: 0.3085 - accuracy: 0.7649 - val_loss: 0.3383 - val_accuracy: 0.7598\n",
      "Epoch 5/6\n",
      "1931/1931 [==============================] - 1412s 731ms/step - loss: 0.2697 - accuracy: 0.7859 - val_loss: 0.3320 - val_accuracy: 0.7675\n",
      "Epoch 6/6\n",
      "1931/1931 [==============================] - 1436s 744ms/step - loss: 0.2424 - accuracy: 0.8012 - val_loss: 0.3276 - val_accuracy: 0.7709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff5390b6f90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(patience=2)]\n",
    "transformer.summary()\n",
    "transformer.compile(\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "transformer.fit(train_ds,\n",
    "                epochs=6, \n",
    "                validation_data=val_ds, \n",
    "                shuffle = True,\n",
    "                callbacks = my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46c24601",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:19:13.045234Z",
     "iopub.status.busy": "2022-02-07T15:19:13.044230Z",
     "iopub.status.idle": "2022-02-07T15:19:21.381262Z",
     "shell.execute_reply": "2022-02-07T15:19:21.380579Z"
    },
    "papermill": {
     "duration": 11.992891,
     "end_time": "2022-02-07T15:19:21.381406",
     "exception": false,
     "start_time": "2022-02-07T15:19:09.388515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ukr</th>\n",
       "      <th>eng</th>\n",
       "      <th>eng_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Том кращий від мене.</td>\n",
       "      <td>[start] tom is better than me[end]</td>\n",
       "      <td>[start] Tom is better than me.[end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Випий ще бокал.</td>\n",
       "      <td>[start] have a glass of beer[end]</td>\n",
       "      <td>[start] Have another drink.[end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Він розмовляє так, ніби він багатій.</td>\n",
       "      <td>[start] he talks as if he were rich[end]      ...</td>\n",
       "      <td>[start] He speaks as if he were rich.[end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Операція - це найкращий вихід.</td>\n",
       "      <td>[start] this is the best way out[end]         ...</td>\n",
       "      <td>[start] Surgery is the best solution.[end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Я не поет.</td>\n",
       "      <td>[start] i am not the poet[end]</td>\n",
       "      <td>[start] I am not a poet.[end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Хіба ти не отримуєш задоволення від вихідних?</td>\n",
       "      <td>[start] arent you enjoying this job on weekend...</td>\n",
       "      <td>[start] Aren't you enjoying your weekend?[end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Мені потрібні яйця.</td>\n",
       "      <td>[start] i need eggs up[end]</td>\n",
       "      <td>[start] I want eggs.[end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Бог знає, що ми потребуємо.</td>\n",
       "      <td>[start] god knows what we need[end]           ...</td>\n",
       "      <td>[start] God knows what we need.[end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Їй цікаво дізнатися, хто прислав квіти.</td>\n",
       "      <td>[start] she wonder where she sent the flowers[...</td>\n",
       "      <td>[start] She is curious to find who sent the fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ти не проти, якщо я скористаюся твоєю машиною?</td>\n",
       "      <td>[start] do you mind if i wear your car[end]   ...</td>\n",
       "      <td>[start] Would you mind if I used your car?[end]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ukr  \\\n",
       "0                            Том кращий від мене.   \n",
       "1                                 Випий ще бокал.   \n",
       "2            Він розмовляє так, ніби він багатій.   \n",
       "3                  Операція - це найкращий вихід.   \n",
       "4                                      Я не поет.   \n",
       "5   Хіба ти не отримуєш задоволення від вихідних?   \n",
       "6                             Мені потрібні яйця.   \n",
       "7                     Бог знає, що ми потребуємо.   \n",
       "8         Їй цікаво дізнатися, хто прислав квіти.   \n",
       "9  Ти не проти, якщо я скористаюся твоєю машиною?   \n",
       "\n",
       "                                                 eng  \\\n",
       "0  [start] tom is better than me[end]                  \n",
       "1   [start] have a glass of beer[end]                  \n",
       "2  [start] he talks as if he were rich[end]      ...   \n",
       "3  [start] this is the best way out[end]         ...   \n",
       "4      [start] i am not the poet[end]                  \n",
       "5  [start] arent you enjoying this job on weekend...   \n",
       "6        [start] i need eggs up[end]                   \n",
       "7  [start] god knows what we need[end]           ...   \n",
       "8  [start] she wonder where she sent the flowers[...   \n",
       "9  [start] do you mind if i wear your car[end]   ...   \n",
       "\n",
       "                                          eng_target  \n",
       "0                [start] Tom is better than me.[end]  \n",
       "1                   [start] Have another drink.[end]  \n",
       "2         [start] He speaks as if he were rich.[end]  \n",
       "3         [start] Surgery is the best solution.[end]  \n",
       "4                      [start] I am not a poet.[end]  \n",
       "5     [start] Aren't you enjoying your weekend?[end]  \n",
       "6                          [start] I want eggs.[end]  \n",
       "7               [start] God knows what we need.[end]  \n",
       "8  [start] She is curious to find who sent the fl...  \n",
       "9    [start] Would you mind if I used your car?[end]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_index_lookup = dict(zip(range(len(eng_vocabulary)), eng_vocabulary))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = ukr_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = eng_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = eng_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "results_on_test = []\n",
    "for _ in range(10):\n",
    "    input_sentence = random.choice(test_list)\n",
    "    test_ukr_texts = input_sentence[1]\n",
    "    test_eng_texts = input_sentence[0]\n",
    "    translated = decode_sequence(test_ukr_texts)\n",
    "    results_on_test.append({'ukr': test_ukr_texts, 'eng': translated, 'eng_target': test_eng_texts})\n",
    "\n",
    "results_on_test_df = pd.DataFrame(results_on_test)\n",
    "results_on_test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8737.066438,
   "end_time": "2022-02-07T15:19:27.563848",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-07T12:53:50.497410",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
